import os
import numpy as np
from skimage.feature import hog
from torchvision import datasets
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

# ======================== è‡ªå®šä¹‰æ•°æ®é›† ========================
class ShapeFeatureDataset(Dataset):
    def __init__(self, train=True):
        self.train = train
        self.cache_file = "train_features_cnn.npz" if train else "test_features_cnn.npz"
        self.expected_dim = 1296

        if os.path.exists(self.cache_file):
            print(f"\U0001F4C2 åŠ è½½ç¼“å­˜ç‰¹å¾ï¼š{self.cache_file}")
            with np.load(self.cache_file) as data:
                if data['features'].shape[1] != self.expected_dim:
                    print(f"âš ï¸ ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼ˆå‘ç° {data['features'].shape[1]}ï¼ŒæœŸæœ› {self.expected_dim}ï¼‰ï¼Œé‡æ–°æå–...")
                    os.remove(self.cache_file)
                    self.__init__(train)
                    return
                self.features = [torch.tensor(f, dtype=torch.float32) for f in data['features']]
                self.labels = [torch.tensor(l, dtype=torch.long) for l in data['labels']]
        else:
            print(f"ğŸ” æ­£åœ¨æå–HOGç‰¹å¾ï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
            self.data = datasets.MNIST(root='./data', train=train, download=True)
            self.features, self.labels = [], []
            for idx, (img, label) in enumerate(zip(self.data.data, self.data.targets)):
                if idx % 1000 == 0:
                    print(f"  è¿›åº¦ï¼š{idx}/{len(self.data.data)}")

                img_resized = Image.fromarray(img.numpy()).resize((28, 28))
                feature = hog(np.array(img_resized),
                              pixels_per_cell=(4, 4),
                              cells_per_block=(2, 2),
                              visualize=False)
                self.features.append(torch.tensor(feature, dtype=torch.float32))
                self.labels.append(torch.tensor(label, dtype=torch.long))
            np.savez(self.cache_file,
                     features=[f.numpy() for f in self.features],
                     labels=[l.item() for l in self.labels])
            print(f"âœ… ç‰¹å¾æå–å®Œæˆï¼Œå·²ç¼“å­˜åˆ° {self.cache_file}")

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        # é‡æ–° reshape æˆä¼ªå›¾åƒ [1, 36, 36]
        reshaped = self.features[idx].view(1, 36, 36)
        return reshaped, self.labels[idx]

# ======================== CNN æ¨¡å‹å®šä¹‰ ========================
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32 * 9 * 9, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))  # -> [16, 18, 18]
        x = self.pool(F.relu(self.conv2(x)))  # -> [32, 9, 9]
        x = x.view(x.size(0), -1)             # å±•å¹³
        x = F.relu(self.fc1(x))
        return self.fc2(x)

# ======================== è®­ç»ƒæµç¨‹ ========================
def train():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    train_dataset = ShapeFeatureDataset(train=True)
    test_dataset = ShapeFeatureDataset(train=False)

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=64)

    model = CNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(5):
        model.train()
        running_loss = 0.0
        for features, labels in train_loader:
            features = features.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        print(f"ğŸ“š Epoch [{epoch + 1}/5], Loss: {running_loss / len(train_loader):.4f}")

    torch.save(model.state_dict(), "cnn_shape.pt")
    print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º cnn_shape.pt")

    # ======================== æµ‹è¯•å‡†ç¡®ç‡ ========================
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for features, labels in test_loader:
            features = features.to(device)
            labels = labels.to(device)
            outputs = model(features)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"ğŸ¯ æµ‹è¯•å‡†ç¡®ç‡ï¼š{100 * correct / total:.2f}%")

# ======================== å¯åŠ¨ ========================
if __name__ == "__main__":
    if os.path.exists("train_features_cnn.npz"):
        os.remove("train_features_cnn.npz")

    train()